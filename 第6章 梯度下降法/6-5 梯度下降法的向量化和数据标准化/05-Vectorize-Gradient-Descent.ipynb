{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度下降法的向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston() # 一定要集中精力在够得着的主要任务上\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "X = X[y < np.max(y)]\n",
    "y = y[y < np.max(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playML.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, seed = 666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81298026026583592"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 别人说你认真学习，又去看fastai，纠结怎么学，不知道该怎么学，又想添加一个web应用\n",
    "# 有不懂的也不要停下来啊，又耽误了10多分钟\n",
    "from playML.LinearRegression import LinearRegression\n",
    "\n",
    "lin_reg1 = LinearRegression()\n",
    "%time lin_reg1.fit_normal(X_train, y_train) # 训练模型\n",
    "lin_reg1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../..\\playML\\LinearRegression.py:35: RuntimeWarning: overflow encountered in square\n",
      "  return np.sum((y - X_b.dot(theta))**2) / len(X_b)\n",
      "../..\\playML\\LinearRegression.py:62: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if np.abs(J(theta, X_b, y)-J(last_theta, X_b, y)) < epsilon:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg2 = LinearRegression()\n",
    "lin_reg2.fit_gd(X_train, y_train) # 就是说eta大或者gradient大的话，都会造成theta值大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.42362000e+01,   0.00000000e+00,   1.81000000e+01,\n",
       "          0.00000000e+00,   6.93000000e-01,   6.34300000e+00,\n",
       "          1.00000000e+02,   1.57410000e+00,   2.40000000e+01,\n",
       "          6.66000000e+02,   2.02000000e+01,   3.96900000e+02,\n",
       "          2.03200000e+01],\n",
       "       [  3.67822000e+00,   0.00000000e+00,   1.81000000e+01,\n",
       "          0.00000000e+00,   7.70000000e-01,   5.36200000e+00,\n",
       "          9.62000000e+01,   2.10360000e+00,   2.40000000e+01,\n",
       "          6.66000000e+02,   2.02000000e+01,   3.80790000e+02,\n",
       "          1.01900000e+01],\n",
       "       [  1.04690000e-01,   4.00000000e+01,   6.41000000e+00,\n",
       "          1.00000000e+00,   4.47000000e-01,   7.26700000e+00,\n",
       "          4.90000000e+01,   4.78720000e+00,   4.00000000e+00,\n",
       "          2.54000000e+02,   1.76000000e+01,   3.89250000e+02,\n",
       "          6.05000000e+00],\n",
       "       [  1.15172000e+00,   0.00000000e+00,   8.14000000e+00,\n",
       "          0.00000000e+00,   5.38000000e-01,   5.70100000e+00,\n",
       "          9.50000000e+01,   3.78720000e+00,   4.00000000e+00,\n",
       "          3.07000000e+02,   2.10000000e+01,   3.58770000e+02,\n",
       "          1.83500000e+01],\n",
       "       [  6.58800000e-02,   0.00000000e+00,   2.46000000e+00,\n",
       "          0.00000000e+00,   4.88000000e-01,   7.76500000e+00,\n",
       "          8.33000000e+01,   2.74100000e+00,   3.00000000e+00,\n",
       "          1.93000000e+02,   1.78000000e+01,   3.95560000e+02,\n",
       "          7.56000000e+00],\n",
       "       [  2.49800000e-02,   0.00000000e+00,   1.89000000e+00,\n",
       "          0.00000000e+00,   5.18000000e-01,   6.54000000e+00,\n",
       "          5.97000000e+01,   6.26690000e+00,   1.00000000e+00,\n",
       "          4.22000000e+02,   1.59000000e+01,   3.89960000e+02,\n",
       "          8.65000000e+00],\n",
       "       [  7.75223000e+00,   0.00000000e+00,   1.81000000e+01,\n",
       "          0.00000000e+00,   7.13000000e-01,   6.30100000e+00,\n",
       "          8.37000000e+01,   2.78310000e+00,   2.40000000e+01,\n",
       "          6.66000000e+02,   2.02000000e+01,   2.72210000e+02,\n",
       "          1.62300000e+01],\n",
       "       [  9.88430000e-01,   0.00000000e+00,   8.14000000e+00,\n",
       "          0.00000000e+00,   5.38000000e-01,   5.81300000e+00,\n",
       "          1.00000000e+02,   4.09520000e+00,   4.00000000e+00,\n",
       "          3.07000000e+02,   2.10000000e+01,   3.94540000e+02,\n",
       "          1.98800000e+01],\n",
       "       [  1.14320000e-01,   0.00000000e+00,   8.56000000e+00,\n",
       "          0.00000000e+00,   5.20000000e-01,   6.78100000e+00,\n",
       "          7.13000000e+01,   2.85610000e+00,   5.00000000e+00,\n",
       "          3.84000000e+02,   2.09000000e+01,   3.95580000e+02,\n",
       "          7.67000000e+00],\n",
       "       [  5.69175000e+00,   0.00000000e+00,   1.81000000e+01,\n",
       "          0.00000000e+00,   5.83000000e-01,   6.11400000e+00,\n",
       "          7.98000000e+01,   3.54590000e+00,   2.40000000e+01,\n",
       "          6.66000000e+02,   2.02000000e+01,   3.92680000e+02,\n",
       "          1.49800000e+01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10, :] # 取10个样本，相差100倍就是很大的差距了，求到的梯度很大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg2.fit_gd(X_train, y_train, eta=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27556634853389228"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg2.score(X_test, y_test) # eta太小，走的又太小，所以要增加次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 653 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time lin_reg2.fit_gd(X_train, y_train, eta=0.000001, n_iters=1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27556634853389228"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg2.score(X_test, y_test) # 还是不够精确"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用梯度下降法前进行数据归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardScaler = StandardScaler()\n",
    "standardScaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_standard = standardScaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 366 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg3 = LinearRegression()\n",
    "%time lin_reg3.fit_gd(X_train_standard, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_standard = standardScaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81298806201222351"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg3.score(X_test_standard, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度下降法的优势"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = 1000\n",
    "n = 5000 # 100*100图像都装不下\n",
    "\n",
    "big_X = np.random.normal(size=(m, n)) # m个样本，n个特征变量形成一个样本向量\n",
    "# 生成随机的已知参数\n",
    "true_theta = np.random.uniform(0.0, 100.0, size=n+1) # 哑巴的世界真安静啊，生成n+1个参数\n",
    "big_y = big_X.dot(true_theta[1:]) + true_theta[0] + np.random.normal(0., 10, size=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_reg1 = LinearRegression()\n",
    "%time big_reg1.fit_normal(big_X, big_y) # 正规化方程解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_reg2 = LinearRegression()\n",
    "%time big_reg2.fit_gd(big_X, big_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 计算梯度比较慢"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
